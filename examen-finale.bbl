\begin{thebibliography}{1}

\bibitem{ZhaouEtAl}
H.~Chen, A.~Waheed, X.~Li, Y.~Wang, J.~Wang, B.~Raj, and M.~I. Abdin, ``On the
  diversity of synthetic data and its impact on training large language
  models,'' {\em arXiv preprint arXiv:2410.15226}, 2024.

\bibitem{antonesi2025transformers}
G.~Antonesi, T.~Cioara, I.~Anghel, V.~Michalakopoulos, E.~Sarmas, and
  L.~Toderean, ``From transformers to large language models: A systematic
  review of ai applications in the energy sector towards agentic digital
  twins,'' {\em arXiv preprint arXiv:2506.06359}, 2025.

\bibitem{narayan2024cookbook}
A.~Narayan, M.~F. Chen, K.~Bhatia, and C.~Re, ``Cookbook: A framework for
  improving llm generative abilities via programmatic data generating
  templates,'' {\em arXiv preprint arXiv:2410.05224}, 2024.

\bibitem{carlini2021extracting}
N.~Carlini, F.~Tramer, E.~Wallace, M.~Jagielski, A.~Herbert-Voss, K.~Lee,
  A.~Roberts, T.~Brown, D.~Song, U.~Erlingsson, {\em et~al.}, ``Extracting
  training data from large language models,'' in {\em 30th USENIX security
  symposium (USENIX Security 21)}, pp.~2633--2650, 2021.

\bibitem{huang2025survey}
L.~Huang, W.~Yu, W.~Ma, W.~Zhong, Z.~Feng, H.~Wang, Q.~Chen, W.~Peng, X.~Feng,
  B.~Qin, {\em et~al.}, ``A survey on hallucination in large language models:
  Principles, taxonomy, challenges, and open questions,'' {\em ACM Transactions
  on Information Systems}, vol.~43, no.~2, pp.~1--55, 2025.

\bibitem{gerlich2025ai}
M.~Gerlich, ``Ai tools in society: Impacts on cognitive offloading and the
  future of critical thinking,'' {\em Societies}, vol.~15, no.~1, p.~6, 2025.

\end{thebibliography}
